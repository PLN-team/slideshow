
---

# Multivariate Poisson Mixture models

  - a PLN model with an additional layer assuming that the latent observations are drawn from a mixture of $K$ multivariate Gaussian components. 
  
  - Each component $k$ have a prior probability $p(i \in k) = \pi_k$ such that $\sum_k \pi_k = 1$. 
  
  Let $C_i\in \{1,\dots,K\}$  be the multinomial variable describing the component of $i$, then
  
$$\begin{array}{rrcl}
    \text{latent layer 1:} & C_i & \sim & \mathcal{M}(1,\pi = (\pi_1,\dots,\pi_K)), \\
    \text{latent layer 2:} &   \mathbf{Z}_i \mid C_i =  k & \sim & 
    \mathcal{N}({\bar{\boldsymbol\mu}}_k + \mathbf{o}_i + \mathbf{x}_i^\top\boldsymbol\Theta, \boldsymbol\Sigma_k),  \quad k = 1,\dots,K. \\
  \text{observation space } &  \mathbf{Y}_i | \mathbf{Z}_i & \sim & \mathcal{P}\left(\exp\{\mathbf{Z}_i\}\right).
    \end{array}$$

The unkwown parameters are 
- $\boldsymbol\Theta$, the matrix of regression parameters
- ${\boldsymbol\mu}_k$, the vector of means in group $k$
- ${\boldsymbol\Sigma}_k$, the variance-covariance matrix in group $k$
- ${\boldsymbol\pi}$ the vector of mixture proportion
- $C_i$, the group membership of sample $i$
  - Estimated by $\tau_{ik} = \hat{\mathbb{P}}(C_i = k|\mathbf{Y}_i)$, some additional variatonal parameters for the mixture

---
# PLN mixture: additional details

## Parametrization of the covariance matrices

When $p$ is large, general forms of ${\boldsymbol\Sigma}^{(k)}$ lead to a prohibitive number of parameters

$\rightsquigarrow$ We include constrained parametrizations of the covariance matrices to reduce the computational burden and avoid over-fitting:

$$\begin{array}{rrcll}
    \text{no restriction:} & \boldsymbol\Sigma_k & = & \text{symmetric} & \text{($ K p (p+1)/2$ parameters),} \\
    \text{diagonal covariances:} & \boldsymbol\Sigma_k & = &\mathrm{diag}({d}_k) & \text{($2 K p$ parameters),} \\
    \text{spherical covariances:} & \boldsymbol\Sigma_k & = &  \sigma_k^2 {I} & \text{($K (p + 1)$ parameters).} \\
\end{array}$$

## Features

- **Optimization**: _"Similar"_ variational framework
  - Weighted sum of PLN fits with .important[weights given by the posterior probabilities] $\tau_{ik}$
- **Model selection**: variational BIC/ICL, need restart and smoothing
  - $\tilde{\text{BIC}}_K = J(\theta, K) - \frac12 \log(n) \mathrm{\#param}$
  - $\tilde{\text{ICL}}_K = \tilde{\text{BIC}}_K - \mathcal{H}_{\mathcal{N}}(K) - \mathcal{H}_{\mathcal{M}}(K)$ (two layers)

---
# Clustering of the oaks samples

```{r PLNmixture oaks, cache = TRUE, results = FALSE}
PLN_mixtures <- 
   PLNmixture(Abundance ~ 1 + offset(log(Offset)), data = oaks,
             clusters = 1:5, control_main = list(cores = 10))
```

The ouput is of class (`PLNmixturefamily`). It a collection of `R` objects:

```{r print PLNmixture offset}
PLN_mixtures
```

`PLNmixturesfamily` has three methods: `plot`, `getModel`, `getBestModel`<sup>1</sup> 

.footnote[[1] Additional help can be found with `?PLNmixturefamily`, `?getBestModel.PLNmixturefamily`, `?plot.PLNmixturefamily`]


---
# Clustering analysis: model selection (I)

The plot function gives you hints about the "right" rank/subspace size of your data

```{r plot PLNmixtures offset, fig.width = 12, fig.height=6}
plot(PLN_mixtures, criteria = c("loglik", "ICL", "BIC"))
```

---
# Clustering analysis: model selection (II)

To extract a particular model from the collection, use `getBestModel`:

```{r extract PLNmixture offset}
myPLN_mix <- getModel(PLN_mixtures, 3)
```

The extracted object has class `PLNmixturefit`. It contains various information plus $K$ components with class `PLNfit`.

<small>
```{r print PLNmixturefit}
myPLN_mix
```

```{r print PLNmixturefit component}
myPLN_mix$components[[1]]
```
</small>

---
# Clustering analysis: model exploration and vizualisation

.pull-left[
```{r PLN clustering 1 fake, eval = FALSE}
myPLN_mix$plot_clustering_pca()
```

```{r PLN clustering 1, echo = FALSE}
myPLN_mix$plot_clustering_pca(main = 'clustering memberships in individual factor map')
```
]

.pull-right[
```{r PLN clustering 2}
myPLN_mix$plot_clustering_data()
```
]

---
# Clustering analysis: validation?

```{r PLN clustering ARI, echo = FALSE, fig.align='center', fig.height=5}
data.frame(
  nb_components  = sapply(PLN_mixtures$models, function(model) model$k),
  ARI = sapply(lapply(PLN_mixtures$models, function(model) model$memberships), aricode::ARI, oaks$tree),
  AMI = sapply(lapply(PLN_mixtures$models, function(model) model$memberships), aricode::AMI, oaks$tree),
  NID = sapply(lapply(PLN_mixtures$models, function(model) model$memberships), aricode::NID, oaks$tree)
) %>%
  tidyr::pivot_longer(-nb_components,names_to = "score") %>%
  dplyr::group_by(score) %>%
  ggplot(aes(x = nb_components, y = value, colour = score)) + geom_line() + theme_bw() + labs(y = "clustering similarity", x = "number of components")
```

<small>
```{r PLN clustering ARI 2}
table(myPLN_mix$memberships, oaks$tree)
```
</small>


---
# Clustering on corrected data I

```{r PLNmixture oaks tree, cache = TRUE, results = FALSE}
PLN_mixtures_tree <- 
   PLNmixture(Abundance ~ 0 + tree + distTOground + offset(log(Offset)), data = oaks,
             clusters = 1:5, control_main = list(cores = 10))
```

```{r plot PLNmixtures cov offset, fig.width = 12, fig.height=6}
plot(PLN_mixtures_tree, criteria = c("loglik", "BIC"))
```

---
# Clustering on corrected data II

```{r PLN clustering cov selec, echo = FALSE}
myPLN_mix_cov <- getBestModel(PLN_mixtures_tree, "BIC")
```


.pull-left[
```{r PLN clustering cov 1 fake, eval = FALSE}
myPLN_mix_cov$plot_clustering_pca()
```

```{r PLN clustering cov 1, echo = FALSE}
myPLN_mix_cov$plot_clustering_pca(main = 'clustering memberships in individual factor map')
```
]

.pull-right[
```{r PLN clustering cov 2}
myPLN_mix_cov$plot_clustering_data()
```
]
